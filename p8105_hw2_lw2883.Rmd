---
title: "homework 2"
author: "Leighanne Wang"
date: "9/24/2020"
output: github_document
---

Setting Up

```{r setup, message = FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

## Problem 1

Define path to dataset

```{r path_to_data_trash}
path_to_data_trash = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset

```{r trashwheel_df}
trashwheel_df =
  read_xlsx(
    path = path_to_data_trash,
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
      sports_balls = round(sports_balls),
      sports_balls = as.integer(sports_balls)
  )
```

Read and clean up the 2018 and 2017 precipitation data

```{r precip 2018 2017}
precip_2018 =
  read_excel(
    path = path_to_data_trash,
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    path = path_to_data_trash,
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation

```{r precip_df}
# create a df to change the name of the months in the combined annual precipitation dataset
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

# bind the two precipitation data from 2018 and 2017 to combine datasets
precip_df =
  bind_rows(precip_2018, precip_2017)

precip_df =
  left_join(precip_df, month_df, by = "month")
```

#### Trashwheel Dataset
The 'trashwheel_df' dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland from 2014 to 2019. It contains information on the number of dumpsters, date the trash was collected (including month and year), the amount of trash collected in weight (tons) and volume (cubic yards) and includes some types of trash that was collected such as plastic bottles and grocery bags. Finally, it also shows the number of homes powered from the collected trash. There are a total of `r nrow(trashwheel_df)` observations in our final dataset.

* The median number of sports balls found in the dumpster in 2017 was **`r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`**.
* The total weight of trash collected was **`r trashwheel_df %>% pull(weight_tons) %>% sum()` tons** and **`r trashwheel_df %>% pull(volume_cubic_yards) %>% sum()`** cubic yards.

#### Precipitation Dataset
The 'precip_df' dataset contains information for the annual precipitation for the years 2017 and 2018 shown by month. There are a total of `r nrow(precip_df)` observations in our final dataset.

* The total precipitation in 2018 was **`r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches**.
* The total precipitation in 2017 was **`r precip_df %>% filter(year == 2017) %>% pull(total) %>% sum()` inches**.

## Problem 2

Read the NYC Transit dataset

```{r transit_df, message = FALSE}
transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    select(Line:Entry, Vending, ADA) %>% 
    janitor::clean_names() %>% 
    mutate(ada = as.logical(ada)  #mutate ada to logical
    )
```

This dataset contains information about the NYC Subway Entrances and Exits. It has information on the routes, subway lines and names, their location (by latitude and longitude), if there is entry in that location, the type of entrance it has, if there are vending machines, and if it is ADA compliant. There are **`r nrow(transit_df)` rows** and **`r ncol(transit_df)` columns** in this dataset. The names have been cleaned in this dataset and the 'ada' variable has been changed from a character to a logical variable.
This data is not considered tidy because the subway route numbers are individual columns, in order for this to be tidy, the subway route number should be a variable and not individual column values.

```{r vending entry}
#to calculate the proportion of entrances/exits without vending that allow entrance vs. don't allow entrance

vending_entry =
  transit_df %>% 
  filter(vending == "NO", entry == "YES") %>% 
  count()

vending_no_entry =
  transit_df %>% 
  filter(vending == "NO") %>% 
  count()
```

* There are **`r transit_df %>% distinct(line, station_name, .keep_all = TRUE) %>% count()`** distinct stations.
* There are **`r transit_df %>% distinct(line, station_name, .keep_all = TRUE) %>% filter(ada == TRUE) %>% count()`** ADA compliant stations.
* The proportion of station entrances/exits without vending that allows entrance is **`r vending_entry/vending_no_entry`**. 

Pivot_longer to make route number and route names as distinct variables. 
```{r transit_tidy}
transit_df =
  mutate(transit_df,
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
)

transit_tidy_data =
  pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_numbers",
    values_to = "route_names",
    names_prefix = "route"
    )
```

* There are **`r transit_tidy_data %>% filter(route_names == "A") %>% distinct(station_name, .keep_all = TRUE) %>% count()`** distinct stations that serve the A train.
* Of the stations that serve the A train, **`r transit_tidy_data %>% filter(route_names == "A") %>% distinct(station_name, .keep_all = TRUE) %>% filter(ada == TRUE) %>% count()`** are ADA compliant.

## Problem 3

FiveThirtyEight data.

Read and clean pols-month.csv. Separate 'mon' variable into 'year', 'month', 'day'; create a 'president' variable from the 'prez_dem' and 'prez-gop' variables and remove 'day' variable.

```{r pols_df, message = FALSE, collapse = TRUE}
# create a df to change the name of the months in the dataset
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  ) %>% 
  mutate(month = as.character(month))

# read in pols-mon.csv file
pols_df =
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names() %>% 
    separate(mon, sep = "-", into = c("year", "month", "day")) %>% 
    mutate(
      month = (recode(month, '01' = "1", '02' = "2", '03' = "3", '04' = "4", '05' = "5", '06' = "6", '07' = "7", '08' = "8", '09' = "9")) 
    ) %>% 
    pivot_longer(
      c(prez_gop, prez_dem),
      names_to = "president",
      names_prefix = "prez_"
      ) %>% 
    filter(value == 1) %>%
    select(-day, -value)

# join the month df and pols df to get the month name
pols_month_df =
  left_join(pols_df, month_df, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name)
```

Read and clean snp.csv
Separate date into year, month, date; arrange by year and month; relocate year and month to the front of dataset. 

```{r snp_df, message = FALSE, collapse = TRUE}
# create a df to change the name of the months in the dataset
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  ) %>% 
  mutate(month = as.character(month))

# read in snp.csv data
snp_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
    separate(date, sep = "/", into = c("month", "day", "year")) %>%
    arrange(year, month) %>% 
    relocate(year, month) %>% 
    select(-day)

# join the month df and snp df to get the month name
snp_month_df =
  left_join(snp_df, month_df, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name)
```

Read, clean, and tidy unemployment.csv

```{r unemployment_df, message = FALSE}
unemployment_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
      jan:dec,
      names_to = "month",
      values_to = "percentage"
    ) %>% 
  mutate(
    month = (recode(month, 'jan' = "January", 'feb' = "February", 'mar' = "March", 'apr' = "April", 'may' = "May", 'jun' = "June", 'jul' = "July", 'aug' = "August", 'sep' = "September", 'oct' = "October", 'nov' = "November", 'dec' = "December")),
    year = (as.character(year))
    ) %>% 
  rename(month_name = month)
```

Merge the 3 datasets into 1
```{r merge}
# join snp into pols
pols_snp_df = 
  left_join(pols_month_df, snp_month_df, by = c("year", "month_name"))

# join unemployment into pols_snp
pols_snp_unemploy_df = 
  left_join(pols_snp_df, unemployment_df, by = c("year", "month_name"))
```

We started off with 3 datasets: pols-month.csv, snp.csv, and unemployment.csv.

* "pols-month" had data on the number of politicians that were democratic or republican from 1947-2015. It contained the date (year and month), the number of republican and democatic senators, representatives, and presidents. There were **`r nrow(pols_month_df)` rows** and **`r ncol(pols_month_df)` columns**. 
* "snp" contained the date of observation (year and month) and the closing value of S&P stock index on that date.  It contained **`r nrow(snp_df)` rows** and **`r ncol(snp_df)` columns**.  
* "unemployment" contained the date (year and month) and the percentage of unemployment at that date.  It contained **`r nrow(unemployment_df)` rows** and **`r ncol(unemployment_df)` columns**. 


The new dataset pols_snp_unemploy_df combines the three previous datasets: pols-month, snp, and unemployment. This data has **`r nrow(pols_snp_unemploy_df)` rows** and **`r ncol(pols_snp_unemploy_df)` columns**. It contains the date (year and month), the number of democratic and republican senators, representatives, and presidents, and the closing value of S&P stock index, and the percentage of unemployment. 