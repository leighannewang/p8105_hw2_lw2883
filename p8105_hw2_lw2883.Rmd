---
title: "homework 2"
author: "Leighanne Wang"
date: "9/24/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
library(haven)
```

## Problem 1

Define path to dataset

```{r path_to_data_trash}
path_to_data_trash = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset

```{r trashwheel_df}
trashwheel_df =
  read_xlsx(
    path = path_to_data_trash,
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
      sports_balls = round(sports_balls),
      sports_balls = as.integer(sports_balls)
  )
```

Read and clean up the 2018 and 2017 precipitation data

```{r precip 2018 2017}
precip_2018 =
  read_excel(
    path = path_to_data_trash,
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    path = path_to_data_trash,
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation

```{r precip_df}
#create a df to change the name of the months in the combined annual precipitation dataset
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

#bind the two precipitation data from 2018 and 2017 to combine datasets
precip_df =
  bind_rows(precip_2018, precip_2017)

precip_df =
  left_join(precip_df, month_df, by = "month")
```

#### Trashwheel Dataset
The 'trashwheel_df' dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland from 2014 to 2019. It contains information on the number of dumpsters, date the trash was collected (including month and year), the amount of trash collected in weight (tons) and volume (cubic yards) and includes some types of trash that was collected such as plastic bottles and grocery bags. Finally, it also shows the number of homes powered from the collected trash. There are a total of `r nrow(trashwheel_df)` observations in our final dataset.

* The median number of sports balls found in the dumpster in 2017 was **`r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`**.
* The total weight of trash collected was **`r trashwheel_df %>% pull(weight_tons) %>% sum()` tons** and **`r trashwheel_df %>% pull(volume_cubic_yards) %>% sum()`** cubic yards.
* The total number of homes powered is **`r trashwheel_df %>% pull(homes_powered) %>% sum()`**.

#### Precipitation Dataset
The 'precip_df' dataset contains information for the annual precipitation for the years 2017 and 2018 shown by month. There are a total of `r nrow(precip_df)` observations in our final dataset.

* The total precipitation in 2018 was **`r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches**.
* The total precipitation in 2017 was **`r precip_df %>% filter(year == 2017) %>% pull(total) %>% sum()` inches**.

## Problem 2

Read the NYC Transit dataset

```{r transit_df}
transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    select(Line:Entry, Vending, ADA) %>% 
    janitor::clean_names() %>% 
    mutate(ada = as.logical(ada)  #mutate ada to logical
    )
```

This dataset contains information about the NYC Subway Entrances and Exits. It has information on the routes, subway lines and names, their location (by latitude and longitude), if there is entry in that location, the type of entrance it has, if there are vending machines, and if it is ADA compliant. There are **`r nrow(transit_df)` rows** and **`r ncol(transit_df)` columns** in this dataset. The names have been cleaned in this dataset and the 'ada' variable has been changed from a character to a logical variable.
This data is not considered tidy because the subway route numbers are individual columns, in order for this to be tidy, the subway route number should be a variable and not individual column values.

* There are **`r transit_df %>% distinct(line, station_name, .keep_all = TRUE) %>% count()`** distinct stations.
* There are **`r transit_df %>% distinct(line, station_name, .keep_all = TRUE) %>% filter(ada == TRUE) %>% count()`** ADA compliant stations.
* The proportion of station entrances/exits without vending that allows entrance is **`r transit_df %>% filter(vending == "NO", entry == "YES") %>% count()/count(transit_df)`**.

Pivot_longer to make route number and route names as distinct variables. 
```{r transit_tidy}
transit_df =
  mutate(transit_df,
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
)

transit_tidy_data =
  pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route numbers",
    values_to = "route names",
    names_prefix = "route"
    )
```

* There are **`r transit_tidy_data %>% distinct(station_name, route_names = "A", .keep_all = TRUE) %>% count()`** distinct stations.
* Of the stations that serve the A train, **`r transit_tidy_data %>% distinct(station_name, route_names = "A", .keep_all = TRUE) %>% filter(ada == TRUE) %>% count()`** are ADA compliant.

## Problem 3

Read the FiveThirtyEight data.

Read and clean pols-month.csv
Separate 'mon' variable into 'year', 'month', 'day'; create a 'president' variable from the 'prez_dem' and 'prez-gop' variables and remove 'day' variable. **need to change month number to month name**

```{r pols_df}
#read in dataset
pols_df =
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names() %>% 
    separate(mon, sep = "-", into = c("year", "month", "day")) %>% 
    pivot_longer(
      c(prez_gop, prez_dem),
      names_to = "president",
      names_prefix = "prez_"
    ) %>% 
    select(-day)
```

Read and clean snp.csv
Separate date into year, month, date; arrange by year and month; relocate year and month to the front of dataset. **need to change month number to month name**

```{r snp_df}
snp_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
    separate(date, sep = "/", into = c("month", "day", "year")) %>%
    arrange(year, month) %>% 
    relocate(year, month) %>% 
    select(-day)
```

Read, clean, and tidy unemployment.csv **need to change month to full month name**

```{r unemployment_df}
unemployment_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
      jan:dec,
      names_to = "month",
      values_to = "percentage"
    )
```

We started off with 3 datasets: pols-month.csv, snp.csv, and unemployment.csv.

* "pols-month" contained the date (year and month), the number of republican and democatic senators, representatives, and presidents. It contained `r nrow(pols_df)` rows and `r ncol(pols_df)` columns. 
* "snp" contained the date of observation (year and month) and the closing value of S&P stock index on that date.  It contained `r nrow(snp_df)` rows and `r ncol(snp_df)` columns.  
* "unemployment" contained the date (year and month) and the percentage of unemployment at that date.  It contained `r nrow(unemployment_df)` rows and `r ncol(unemployment_df)` columns. 

The new dataset...